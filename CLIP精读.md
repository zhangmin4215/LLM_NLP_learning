0、摘要  
* 当前最先进的计算机视觉系统经过训练，只能用于预测一组预先设定的固定物体类别。
* 直接从图像相关的原始文本中学习是一种极具前景的替代方案，这种方法能利用更广泛的监督信号来源。
* 预训练完成后，系统可直接利用自然语言调用已习得的视觉概念（或描述新概念），从而实现模型在下游任务中的零样本(zero-shot)迁移。

1、引言  
* 直接从原始文本中学习的预训练方法，已经彻底改变了自然语言处理领域的发展格局。（以BERT、GPT为代表的自监督预训练范式）
* 基于自回归建模和掩码语言建模等任务无关的预训练目标，已在算力、模型容量和数据规模上实现多数量级扩展，持续推动模型能力提升。
* "文本到文本"标准化输入输出接口(T5)的发展，使任务无关的模型架构能够零样本迁移至下游数据集，从而消除了对专用输出头（specialized output heads）或数据集定制化（dataset-specific customization）的需求。
* 在这种文本进文本出、利用自监督的信号去训练整个模型的框架，大规模的没有标注的数据比那些手工标注的数据效果更好
