0、摘要  
* 当前最先进的计算机视觉系统经过训练，只能用于预测一组预先设定的固定物体类别。
* 直接从图像相关的原始文本中学习是一种极具前景的替代方案，这种方法能利用更广泛的监督信号来源。
* 预训练完成后，系统可直接利用自然语言调用已习得的视觉概念（或描述新概念），从而实现模型在下游任务中的零样本(zero-shot)迁移。

1、引言  
* 直接从原始文本中学习的预训练方法，已经彻底改变了自然语言处理领域的发展格局。（以BERT、GPT为代表的自监督预训练范式）
* 基于自回归建模和掩码语言建模等任务无关的预训练目标，已在算力、模型容量和数据规模上实现多数量级扩展，持续推动模型能力提升。
* "文本到文本"标准化输入输出接口(T5)的发展，使任务无关的模型架构能够零样本迁移至下游数据集，从而消除了对专用输出头（specialized output heads）或数据集定制化（dataset-specific customization）的需求。
* 在这种文本进文本出、利用自监督的信号去训练整个模型的框架，大规模的没有标注的数据比那些手工标注的数据效果更好

2、方法  
2.1自然语言监督  
* 我们方法的核心思想，是从自然语言蕴含的监督信息中学习感知能力。
* 具有上下文语义环境的学习方式(bert用的完形填空)
* 与其他训练方法相比，从自然语言中学习具有若干潜在优势。相比需要将标注结果处理成标准机器学习格式（比如图像分类任务中的“N选1”黄金标签）的传统人工标注，基于自然语言的监督训练更容易扩展规模，因为它天然就符合人类表达习惯，无需额外格式转换。相比之下，基于自然语言的方法可以直接从互联网海量文本中被动地学习有效信息，无需人工主动标注。
* 它不仅能让模型学习到特征表示，还能将这些特征与语言关联起来——这种特性让模型无需额外训练（ zero-shot）就能灵活迁移到新任务中。

2.2创建一个足够大的数据集  
400 million (image, text) pairs

2.3选择一个有效的预训练方法  
我们最初采用相同的词袋编码（Bag-of-Words）作为基准方法，随后在图2中将预测目标替换为对比学习目标，结果发现：模型在ImageNet上的零样本迁移效率又提升了4倍。  
(预测目标：给定一张图片，预测对应的文本，会有很多可能；对比学习目标：只需要判断图片和文本是不是配对)

