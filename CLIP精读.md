0、摘要  
* 当前最先进的计算机视觉系统经过训练，只能用于预测一组预先设定的固定物体类别。
* 直接从图像相关的原始文本中学习是一种极具前景的替代方案，这种方法能利用更广泛的监督信号来源。
* 预训练完成后，系统可直接利用自然语言调用已习得的视觉概念（或描述新概念），从而实现模型在下游任务中的零样本(zero-shot)迁移。

1、引言  
* 直接从原始文本中学习的预训练方法，已经彻底改变了自然语言处理领域的发展格局。（以BERT、GPT为代表的自监督预训练范式）
* 基于自回归建模和掩码语言建模等任务无关的预训练目标，已在算力、模型容量和数据规模上实现多数量级扩展，持续推动模型能力提升。
* "文本到文本"标准化输入输出接口(T5)的发展，使任务无关的模型架构能够零样本迁移至下游数据集，从而消除了对专用输出头（specialized output heads）或数据集定制化（dataset-specific customization）的需求。
* 在这种文本进文本出、利用自监督的信号去训练整个模型的框架，大规模的没有标注的数据比那些手工标注的数据效果更好

2、方法  
2.1自然语言监督  
* 我们方法的核心思想，是从自然语言蕴含的监督信息中学习感知能力。
* 具有上下文语义环境的学习方式(bert用的完形填空)
* 与其他训练方法相比，从自然语言中学习具有若干潜在优势。相比需要将标注结果处理成标准机器学习格式（比如图像分类任务中的“N选1”黄金标签）的传统人工标注，基于自然语言的监督训练更容易扩展规模，因为它天然就符合人类表达习惯，无需额外格式转换。相比之下，基于自然语言的方法可以直接从互联网海量文本中被动地学习有效信息，无需人工主动标注。
* 它不仅能让模型学习到特征表示，还能将这些特征与语言关联起来——这种特性让模型无需额外训练（ zero-shot）就能灵活迁移到新任务中。

2.2创建一个足够大的数据集  
400 million (image, text) pairs

2.3选择一个有效的预训练方法  
我们最初采用相同的词袋编码（Bag-of-Words）作为基准方法，随后在图2中将预测目标替换为对比学习目标，结果发现：模型在ImageNet上的零样本迁移效率又提升了4倍。  
(预测目标：给定一张图片，预测对应的文本，会有很多可能；对比学习目标：只需要判断图片和文本是不是配对)

视觉模型选择：resnet或VIT  
文本模型选择：transformer  

2.5训练  
使用Adam优化器  
V100 GPUs  

3.实验  
3.1 Zero-Shot Transfer  
当前无监督学习领域的研究大多聚焦于机器学习系统的特征提取能力(representation learning)[下游任务还是需要标签进行微调]，而我们的研究则另辟蹊径——通过测试系统的零样本迁移能力，来评估其真正的任务学习能力[用文本作为引导，灵活地做zero shot的迁移学习，在分类任务上效果特别好]。

3.2 使用CLIP进行ZERO-SHOT推理  
![image](https://github.com/user-attachments/assets/7d97df87-7a04-40e4-94d1-12a691559f4a)
* CLIP预训练好后，有两个编码器：image encoder和text encoder
* 任意给定一张照片，通过图片编码器会得到一个图片的特征I1
* 你感兴趣的标签(plane/car/dog/bird)，这四个词通过prompt engeering就会变成一个句子(A photo of a {object})，四个单词就变成四个句子。通过文本编码器，得到四个文本的特征T1、T2、T3、TN
* 拿四个文本特征和一个图像特征计算cosine similarity，最后得到的相似度会通过一层softmax得到概率分布。

3.1.4 PROMPT ENGINEERING AND ENSEMBLING提示工程与模型集成
* 一个常见的问题是一词多义
* 我们在预训练数据中还发现一个现象：图像所配的文本很少是单个单词
* 为了解决这种数据分布差异，我们发现一个很管用的默认模版( prompt template)："A photo of a {label}."（这个固定句式能明确提示文本需要描述图片内容）
* 对于动物数据集，可以设置提示模版：A photo of a {label}, a type of pet.
* 在OCR任务中，我们发现：给需要识别的文字或数字加上引号，就能显著提升识别准确率。
* 多用提示模版(80个)做多次推理，最后把结果综合起来。Prompt ensembling

3.2 特征学习(Representation Learning)  
下游任务用全部的数据，有多种方式衡量模型学到的特征好不好。一种是：linear probe，把预训练好的模型冻住，然后在上面训练一个分类头(只有最后一层fc可以训练)；另外一种：fine tuning，把整个网络都放开，直接做端到端的学习
