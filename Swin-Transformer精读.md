Swin Transformer: Hierarchical Vision Transformer using Shifted Windows  
基于移位窗口的分层ViT

0.摘要  
* 将Transformer从语言领域迁移到视觉领域所面临的挑战，主要源于二者之间的本质差异，例如：视觉实体的尺度变化更为显著，且图像像素的分辨率远高于文本中的单词。
* 这种移位窗口的机制通过将自注意力计算限制在非重叠的局部窗口内，显著提升了计算效率，同时仍保留了跨窗口的连接能力。
* 这种分层架构具有多尺度建模的灵活性，并且其计算复杂度与图像大小呈线性关系。

1.引言  
![image](https://github.com/user-attachments/assets/ecf9ec81-e5fb-4448-a1b7-06acaace9e8e)
* 提出的Swin Transformer通过深层合并图像块（如灰色区域所示），构建分层特征图。由于自注意力计算仅在各局部窗口内进行（如红色区域所示），其计算复杂度与输入图像尺寸呈线性关系。因此，该模型可作为通用骨干网络，同时适用于图像分类和密集预测任务。
* 卷积神经网络通过pooling池化(文中的类似操作是patch merging)得到多尺度的特征，能增大每个卷积核看到的感受野
* 一旦有了多尺寸的特征信息，输给一个FPN就可以做检测任务；输给一个UNet，就可以做分割任务
